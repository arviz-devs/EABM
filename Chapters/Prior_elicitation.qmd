# Prior Elicitation  {#sec-prior-elicitation}

```{python}
#| echo : false
import arviz_plots as azp
import numpy as np
import preliz as pz
import matplotlib.pyplot as plt
rng = np.random.default_rng(793)
azp.style.use("arviz-clean")
```

Specification of the prior distribution for a Bayesian model is key, but it is often difficult even for statistical experts. Having to choose a prior distribution is portrayed both as a burden and as a blessing. We choose to affirm that is a necessity, if you are not choosing your priors someone else is doing it for you @Mikkola_2024. Letting others decide for you is not always a bad idea. Default priors provided by tools like [Bambi](https://github.com/bambinos/bambi) or [brms](http://paulbuerkner.com/brms/) can be very useful in many problems, but it's advantageous to be able to specify custom priors when needed.

![Having to set priors are often seen as a burden, a nuisance of Bayesian statistics](../img/prior_anxiety.png){#fig-prior_anxiety width=30%}

The process of transforming domain knowledge into well-defined prior distributions is called Prior Elicitation and as we already said is an important part of Bayesian modelling. In this chapter, we will discuss some general approaches to prior elicitation and provide some examples. Two other sources of information about prior elicitation that complement this chapter are the [PreliZ documentation](https://preliz.readthedocs.io), a Python package for prior elicitation that we will discuss here, and [PriorDB](https://n-kall.github.io/priorDB/), a database of prior distributions for Bayesian analysis. 

## Priors and Bayesian Statistics

If you are reading this guide, you probably already know what a prior distribution is. But let's do a quick recap. In Bayesian statistics, the prior distribution is the probability distribution that expresses information about the parameters of the model before observing the data. The prior distribution is combined with the likelihood to obtain the posterior distribution, which is the distribution of the parameters after observing the data.

Priors are one way to convey domain-knowledge information into models. Other ways to include information in a model are the type of model or its overall structure, e.g. using a linear model, and the choice of likelihood. Nevertheless, usually, the selling point when discussing in favour of priors is that they allow the inclusion of domain information. But there are potentially other advantages:

* Sampling efficiency. Often a more informed priors results in better sampling. This does not mean we should tweak the prior distribution to solve sampling problems, instead incorporating some domain-knowledge information can help to avoid them.
* Regularization. More informed priors can help to regularize the model, reducing the risk of overfitting. We make a distinction between regularization and "conveying domain-knowledge information" because motivations and justifications can be different in each case.


## Types of Priors


Usually, priors are described as informative vs non-informative. Informative priors are priors that convey specific information about the parameters of the model, while non-informative priors do not convey specific information about the parameters of the model. Non-informative priors are often used when little or no domain knowledge is available. A simple, intuitive and old rule for specifying a non-informative prior is the principle of indifference, which assigns the same probability to all possible events. Non-informative priors are also called objective priors especially when the main motivation for using them is to avoid the need to specify a prior distribution.

Non-informative priors can be detrimental and difficult to implement or use. Informative priors can also be problematic in practice, as the information needed to specify them may be absent or difficult to obtain. And even if the information is available specifying informative priors can be time-consuming. A middle ground is to use weakly informative priors, which are priors that convey some information about the parameters of the model but are not overly specific. Weakly informative priors can help to regularize inference and even have positive side effects like improving sampling efficiency.

![Priors are often defined in terms of how much information they convey](../img/priors_int_meme.jpg){#fig-prior_type_meme width=35%}

It is important to recognize that the amount of information a priors carry can vary continuously and that the categories we use to discuss priors are a matter of convenience and not a matter of principle. These categories are qualitative and not well-defined. Still, they can be helpful when talking about priors more intuitively. 

So far we have discussed the amount of information. There are at least two issues that seem fishy about this discussion. First, the amount of information is a relative concept, against what are we evaluating if a prior is informative or not? Second, the amount of information does not necessarily mean the information is _good_ or _correct_. For instance, it's possible to have a very informative prior based on wrong assumptions. Thus when we say _informative_ we don't necessarily mean reliable or that the prior will bias the inference in the correct direction and amount. 

There is one way to frame the discussion about priors that can help to address these issues. That is to think about priors in terms of the prior predictive distribution they induce. In other words, we think about the priors in terms of their predictions about unobserved, potentially observable data. This mental scaffold can be helpful in many ways:

* First, it naturally leads us to think about priors in relation to other priors and the likelihood, i.e. it reflects the fact that we cannot understand a prior without the context of the model @gelman_2017. 
* Second, it gives us an operational definition of what we mean by vague, informative, or weakly informative prior.  An informative prior is a prior that makes predictions that are about the same. A weakly informative prior is a prior that makes predictions that are somewhere in between. The distinctions are still qualitative and subjective, but we have a criteria that is context-dependent and we can evaluate during a Bayesian data analysis. Figure @fig-prior_vagueness shows a very schematic representation of this idea.
* Third, it provides us with a way to evaluate the priors for consistency, because the priors we are setting should agree with the prior predictive distribution we imagine. For instance, if we are setting an informative prior that induces a prior predictive distribution that is narrower, shifted or very different in any other way from the one we imagine either the prior or our expectation of the prior predictive distribution is wrong. We have specified two conflicting pieces of information. Reconciling these two pieces of information does not guarantee that the prior or any other part of the model is correct, but it provides internal consistency, which is a good starting point for a model.

![Prior amount of information in terms of the prior predictive distribution induced by them](../img/prior_vagueness.png){#fig-prior_vagueness}

Using the prior predictive distribution to evaluate priors is inherently a global approach, as it assesses the combined impact of all priors and the likelihood. However, during prior elicitation, we may sometimes focus on making one or two priors more informative while keeping the others vague. In these cases, we can think of this as having a "local" mix of priors with varying levels of informativeness. In practice, we often balance this global perspective with the local approach, tailoring priors to the specific needs of the model.


## Bayesian Workflow for Prior Elicitation

It is important to think of prior elicitation in the context of a flexible workflow adapting to the specific needs of the model and the data. The workflow should also be iterative, as prior elicitation may need to be revisited as the model is developed and the data are analysed.

Knowing when to perform prior elicitation is central to a prior elicitation workflow. In some situations, default priors and models may be sufficient, especially for routine inference that applies the same, or very similar, model to similar new datasets. But even for new datasets, default priors can be a good starting point, adjusting them only after initial analysis reveals issues with the posterior or computational problems. As with other components of the Bayesian workflow, prior elicitation isn’t just a one-time task. It's not even one that is always done at the beginning of the analysis. 

For simple models with strong data, the prior may have minimal impact, and starting with default or weakly informed priors may be more appropriate and provide better results than attempting to generate very informative priors. The key is knowing when it’s worth investing resources in prior elicitation. Or more nuanced how much time and domain knowledge is needed in prior specification. Usually, getting rough estimates can be sufficient to improve inference. Thus, in practice, weakly informative priors are often enough. In a model with many parameters eliciting all of them one by one may be too time-consuming and not worth the effort. Refining just a few priors in a model can be sufficient to improve inference.

The prior elicitation process should also include a step to verify the usefulness of the information and assess how sensitive the results are to the choice of priors, including potential conflicts with the data. This process can help identify when more or less informative priors are needed and when the model may need to be adjusted.

Finally, we want to highlight that prior elicitation isn't just about choosing the _right_ prior but also about understanding the model and the problem. So even if we end up with a prior that has little impact on the posterior, compared to a vague or default prior, performing prior elicitation could be useful for the modeller. Especially among newcomers setting priors can be seen as an anxiogenic task. Spending some time thinking about priors, with the help of proper tools, can help reduce this brain drain and save mental resources for other modelling tasks.


## Priors and entropy

The entropy is a property of probability distributions the same way the mean or variance are, actually it's the expected value of the negative log probability of the distribution. We can think of entropy as a measure of the information or uncertainty of a distribution has. Loosely speaking the entropy of a distribution is high when the distribution is spread out and low when the distribution is concentrated. In the context of prior elicitation maximum entropy can be a guiding principle to pick priors. According to this principle we should choose the prior that maximizes the entropy, subject to known constraints of the prior @jaynes_2003. This is a way to choose a prior that is as _vague_ as possible, given the information we have. Figure @fig-max_ent shows a distribution with support in [0, 1]. On the first panel we have the distribution with maximum entropy and no other restrictions. We can see that this is a uniform distribution. On the middle we have the distribution with maximum entropy and a given mean. This distribution looks similar to an exponential distribution. On the last panel we have the distribution with maximum entropy and 70% of its mass between 0.5 and 0.75. 

![3 maximum entropy distributions subject to different constrains](../img/max_ent.png){#fig-max_ent}

For some priors in a model, we may know or assume that most of the mass is within a certain interval. This information is useful for determining a suitable prior, but this information alone may not be enough to obtain a unique set of parameters. @fig-beta_bounds shows Beta distributions with 90% of the mass between 0.1 and 0.7. As you can see we can obtain very different distributions, conveying very different prior knowledge. The red distribution is the one with maximum entropy, given the constraints.

![Beta distributions with a 90% of it mass between 0.1 and 0.7, the red one is the one with maximum entropy](../img/beta_bounds.png){#fig-beta_bounds}


## Preliz

[PreliZ](https://preliz.readthedocs.io) @icazatti_2023 is a Python package that helps practitioners choose prior distributions by offering a set of tools for the various facets of prior elicitation. It covers a range of methods, from unidimensional prior elicitation on the parameter space to predictive elicitation on the observed space. The goal is to be compatible with probabilistic programming languages (PPL) in the Python ecosystem like PyMC and PyStan, while remaining agnostic of any specific PPL.

### Maximum entropy distributions with maxent

In PreliZ we can compute maximum entropy priors using the function `maxent`. It works for unidimensional distributions. The first argument is a PreliZ distribution. Then we specify an upper and lower bounds and then the probability inside the range defined by the bounds.

Let's say that we want to elicit a scale parameter and from domain knowledge we know that the parameter has a relatively high probability of being less than 3. In that case we could use a HalfNormal and then do:

```{python}
pz.maxent(pz.HalfNormal(), 0, 3, 0.8);
```

When we want to avoid values too close to zero, other distributions like Gamma or InverseGamma may be a better choice.

```{python}
pz.maxent(pz.Gamma(), 0, 3, 0.8);
```

Furthermore, we may have more information that just a plausible range. We could also has extra restrictions like knowledge about the mean or mode. Let's say we think a mean of 2 is very likely, then we can take advantage of the fact that the Gamma can also be parametrized in terms of the mean and pass the distribution `pz.Gamma(mu=2)`. If instead we think is the mode the one is likely to be 2, then `maxent` has a `mode` argument we can use.
```{python}
dist_mean = pz.Gamma(mu=2)
pz.maxent(dist_mean, 0, 3, 0.8)

dist_mode = pz.Gamma()
pz.maxent(dist_mode, 0, 3, 0.8, mode=2);
```

Notice that if you call `maxent` several times in the same cell, as we just did, we will get all the distributions in the same plot. This can be very useful to visually compare several alternatives.

The function `maxent` as others in PreliZ modify distribution in place, so a common workflow is to instantiate a distribution first, perform the elicitation, and then inspect its properties, plot it, or use it in some other way. For instance, we may want to check a summary of some of its properties:

```{python}
dist_mean.summary(), dist_mode.summary()
```

### Other direct elicitation methods from PreliZ

There are many other method for direct elicitation of parameters. For instance the [quartile](https://preliz.readthedocs.io/en/latest/unidimensional.html#preliz.unidimensional.quartile) functions identifies a distribution that matches specified
quartiles, and [Quartine_int](https://preliz.readthedocs.io/en/latest/unidimensional.html#preliz.unidimensional.QuartileInt) provides an interactive approach to achieve the same, offering a more hands-on experience for refining distributions.

One method worth of special mention is the [Roulette](https://preliz.readthedocs.io/en/latest/unidimensional.html#preliz.unidimensional.Roulette) method allows which allows users to find a prior distribution by drawing it interactively @morris_2014. The name "roulette" comes from the analogy of placing a limited set of chips where one believes the mass of a distribution should be concentrated. In this method, a grid of `m` equally sized bins is provided, covering the range of `x`, and users allocate a total of `n` chips across the bins. Effectively, this creates a histogram,representing the user's information about the distribution. The method then identifies the best-fitting distribution from a predefined pool of options, translating the drawn histogram into a suitable probabilistic model. 

As this is an interactive method we can't show it here, but you can run the following cell to see how it works.

```{python}
#| eval : false
%matplotlib widget
result = pz.Roulette()
```

And this gif should give you an idea on how to use it.

![To elicit a distribution, we can interactively *draw* a histogram, and Roulette will identify the distribution that best matches it.](../img/roulette.gif){#fig-prior_anxiety}



Once we have elicited the distribution we can call `.dist` attribute to get the selected distribution. In this example, it will be `result.dist`. 

If needed, we can combine results for many independent "roulette sessions" with the [combine_roulette](https://preliz.readthedocs.io/en/latest/unidimensional.html#preliz.unidimensional.combine_roulette) function. Combining information from different elicitation sessions can be useful to aggregate information from different domain experts. Or even from a single person unable to pick a single option. For instance if we run `Roulette` twice, and for the first one we get `result0` and for the second `result1`. Then, we can combine both solutions into a single one using:

```{python}
#| eval : false
pz.combine_roulette([result0.inputs, result1.inputs], weights=[0.3, 0.7])
```

In this example, we assign a larger weight to the results from the second elicitation session, we can do this to reflect uneven degrees of trust. By default, all sessions are weighted equally.

### Predictive elicitation